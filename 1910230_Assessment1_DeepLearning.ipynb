{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dayanakhadijah/DLCV-Workshop-Assignments/blob/main/1910230_Assessment1_DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpRNh1-L8zuk"
      },
      "source": [
        "## Assessment 1: Deep Learning\n",
        "\n",
        "1) Answer all questions.\n",
        "2) This assessment is open-book. You are allowed to refer to any references including online materials, books, notes, codes, github links, etc.\n",
        "3) Copy this notebook to your google drive (click **FILE** > **save a copy in Drive**)\n",
        "4) Upload the answer notebook to your github. \n",
        "5) Submit the assessment by sharing the link to your answer notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjRauIpz8zun"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**QUESTION 1** \n",
        "\n",
        "One day while wandering around a clothing store at KL East Mall, you stumbled upon a pretty girl who is choosing a dress for Hari Raya. It turns out that the girl is visually impaired and had a hard time distinguishing between an abaya and a kebaya. To help people with the similar situation, you then decided to develop an AI system to identify the type of clothes using a Convolutional Neural Networks (ConvNet). In order to train the network, you decide to use the Fashion MNIST dataset which is freely available on Pytorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzzvkxpn8zuo"
      },
      "source": [
        "a) Given the problem, what is the most appropriate loss function to use? Justify your answer. **[5 marks]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0hERYSq8zuo"
      },
      "source": [
        "\n",
        "<span style=\"color:blue\">\n",
        "    ANSWER: Huber Loss. Huber Loss is a combination of the mean squared error and the mean absolute error, but it only takes the benefits of them. The MSE works well with small errors that have minimal effect on the regression line but causes maximum errors that causes problems on the loss function in the case of outliers. Meanwhile, the MAE is the opposite of MSE, it is more robust in the case of outliers, but have maximum effect on the regression line for small difference. So, the Huber Loss takes the positive of MAE and MSE, which makes it works well with small errors and robust in the case of outliers. </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW6A4Pmj8zuo"
      },
      "source": [
        "b) Create and train a ConvNet corresponding to the following CNN architecture (with a modification of the final layer to address the number of classes). Please include **[10 marks]**:\n",
        "\n",
        "    1) The dataloader to load the train and test datasets.\n",
        "\n",
        "    2) The model definition (either using sequential method OR pytorch class method).\n",
        "\n",
        "    3) Define your training loop.\n",
        "\n",
        "    4) Output the mean accuracy for the whole testing dataset.\n",
        "\n",
        "    \n",
        "\n",
        "<div>\n",
        "<img src=\"https://vitalflux.com/wp-content/uploads/2021/11/VGG16-CNN-Architecture.png\" width=\"550\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5Ue0OHCL8zup"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "###################################################\n",
        "######## THE REST OF THE CODES DOWN HERE ##########\n",
        "###################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1) The dataloader to load the train and test datasets.\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n",
        "train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('./data', download=True, train=False, transform=transform)\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=True)\n",
        "\n",
        "# classes of fashion mnist dataset\n",
        "classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
        "\n",
        "train_data_size = len(train_loader.dataset)\n",
        "test_data_size = len(test_loader.dataset)\n",
        "\n",
        "print(train_data_size)\n",
        "print(test_data_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457,
          "referenced_widgets": [
            "a9549e96fc794ffe9b94c91433f3d103",
            "f4f7c83b7e7d4b78a11d389db5f303e8",
            "2c2c9ca375d94e70b1edf76003941150",
            "fd47839b98794336bc8c4fbf4c5ec72e",
            "47bf47de2dc5417a8f721432c755ae54",
            "96df4e5d6fb84b388bc0d3a030df205d",
            "612acdb6f82646959f1c47ee2f0d03aa",
            "ca2c1816b56f46a380b2c464f7b106cf",
            "b75a48d820c14df2893d5f2af4f0cef7",
            "ec46d8c8011b481ea58decf4a5865e87",
            "87d1d591896d41ab9a88041a37513999",
            "65d0880e3b464648a1b34d1451ed3953",
            "60d8898020c448899b4068867520fed0",
            "ae48b10cb20f45c8ab62e238c24727c2",
            "d1368d494b334b51b97944bde8be34a0",
            "f9ace680701f4daea623ac20e6d4ba08",
            "636b0bb2f0b64be6b3e3cf209b1c20df",
            "9e47ca669de44dd59534297de1e1364e",
            "624feaeab71648be868a13555dda6323",
            "3d7c1abfd3034189bc81e9737c067a5e",
            "51b78bd8d2d8454ba36869c5f6b2cd2c",
            "954a1d03f2734d8cbeae992b1787b380",
            "2e5a99203e2e47bebe7cdcd5ef85a87e",
            "af442801ba884d3d93b663decb7f9c86",
            "6aaaf93609ca4499915215aef7a78158",
            "e2ab9dfae8394eb3abf97fdaa44180a6",
            "baccb0946d504b50bd477b5311d5b661",
            "43c34f7fc3954791a45e2a4ab6ae08cf",
            "7ed6e0dd9a974768ba4c021f5f883085",
            "5bc8ed2b704b41e0b26c0baceb8b7799",
            "92f50b50640241a88aa46d2157fb2cbd",
            "3d25a927002b459f95a40058d0689fed",
            "882cc8a4f2284df9bf1e4ad4c384a103",
            "6a3f7182c6d6469690ed4dc190a40652",
            "50edf6972be448fca2883e4be2c671a7",
            "540e9ab5e7c44d1485e3740028f3603d",
            "a7658cb301a74dc385c359c027427e0e",
            "dac90f7cafee442ebf9019c6bad712e7",
            "86c9ba3c21b24ccbadc12dff3e49b441",
            "32c38e0f2d9f4097ad4e0516d6e74f30",
            "6241ae7d584f4fb7ac8fdffec905f3fc",
            "3160bf952d334e54a0ec7d1bd538d7de",
            "7bfe5383d1554944b835ce2a81960aaa",
            "933c4ca6d559416d87584f438afc8605"
          ]
        },
        "id": "nbTZu_KxJxkb",
        "outputId": "ce379d9a-01a9-42b8-f85f-83987b9f3c1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26421880 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9549e96fc794ffe9b94c91433f3d103"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/29515 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65d0880e3b464648a1b34d1451ed3953"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4422102 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e5a99203e2e47bebe7cdcd5ef85a87e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a3f7182c6d6469690ed4dc190a40652"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2) The model definition (either using sequential method OR pytorch class method).\n",
        "# Class method:\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3, padding=2)\n",
        "        self.conv5 = nn.Conv2d(512, 512, 1)\n",
        "        self.fc6 = nn.Linear(512 * 1 * 1, 4096)\n",
        "        self.fc7 = nn.Linear(4096, 1000)\n",
        "        self.fc8 = nn.Linear(1000, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = self.pool(self.relu(self.conv4(x)))\n",
        "        x = self.pool(self.relu(self.conv5(x)))\n",
        "        x = x.view(-1, 512 * 1 * 1)\n",
        "        x = self.relu(self.fc6(x))\n",
        "        x = self.relu(self.fc7(x))\n",
        "        x = self.fc8(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1x0EVv9jJ2FF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3) Define your training loop.\n",
        "#3a) LOSS and OPTIMIZER\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaEd3DHnQnWB",
        "outputId": "0ff973ba-a1b7-4bb8-cc12-840c2fb8ed43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "  (conv5): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (fc6): Linear(in_features=512, out_features=4096, bias=True)\n",
              "  (fc7): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (fc8): Linear(in_features=1000, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3b) Define your training loop.\n",
        "\n",
        "import time # to calculate training time\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "            \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(test_loader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "            \n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_test_loss = valid_loss/test_data_size \n",
        "        avg_test_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
        "        \n",
        "        # Save if the model has best accuracy till now\n",
        "        torch.save(model, 'fashionMNIST_model_'+str(epoch)+'.pt')\n",
        "            \n",
        "    return model, history"
      ],
      "metadata": {
        "id": "JRl3grUsQ_nd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3c) Training\n",
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(model, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMkgMmfUSTh2",
        "outputId": "0cbe96ae-a1d2-4445-9a75-53818b772bbb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10\n",
            "Epoch : 000, Training: Loss: 2.3004, Accuracy: 16.6617%, \n",
            "\t\tValidation : Loss : 2.2963, Accuracy: 31.1300%, Time: 27.0113s\n",
            "Epoch: 2/10\n",
            "Epoch : 001, Training: Loss: 2.1551, Accuracy: 33.8383%, \n",
            "\t\tValidation : Loss : 1.3206, Accuracy: 52.0100%, Time: 20.2782s\n",
            "Epoch: 3/10\n",
            "Epoch : 002, Training: Loss: 0.8587, Accuracy: 67.0450%, \n",
            "\t\tValidation : Loss : 0.6805, Accuracy: 73.9800%, Time: 21.1831s\n",
            "Epoch: 4/10\n",
            "Epoch : 003, Training: Loss: 0.6035, Accuracy: 77.1300%, \n",
            "\t\tValidation : Loss : 0.5696, Accuracy: 78.0800%, Time: 20.3728s\n",
            "Epoch: 5/10\n",
            "Epoch : 004, Training: Loss: 0.5278, Accuracy: 79.9283%, \n",
            "\t\tValidation : Loss : 0.5140, Accuracy: 80.7200%, Time: 20.2580s\n",
            "Epoch: 6/10\n",
            "Epoch : 005, Training: Loss: 0.4744, Accuracy: 82.2617%, \n",
            "\t\tValidation : Loss : 0.5003, Accuracy: 81.2500%, Time: 20.8600s\n",
            "Epoch: 7/10\n",
            "Epoch : 006, Training: Loss: 0.4291, Accuracy: 84.1083%, \n",
            "\t\tValidation : Loss : 0.4337, Accuracy: 84.0400%, Time: 20.2888s\n",
            "Epoch: 8/10\n",
            "Epoch : 007, Training: Loss: 0.3892, Accuracy: 85.6200%, \n",
            "\t\tValidation : Loss : 0.4117, Accuracy: 84.7300%, Time: 20.1903s\n",
            "Epoch: 9/10\n",
            "Epoch : 008, Training: Loss: 0.3616, Accuracy: 86.7117%, \n",
            "\t\tValidation : Loss : 0.3706, Accuracy: 86.3700%, Time: 20.1651s\n",
            "Epoch: 10/10\n",
            "Epoch : 009, Training: Loss: 0.3352, Accuracy: 87.6583%, \n",
            "\t\tValidation : Loss : 0.3802, Accuracy: 86.1400%, Time: 20.3467s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3d) Loss and Accuracy Curve\n",
        "history = np.array(history)\n",
        "plt.plot(history[:,0:2])\n",
        "plt.legend(['Tr Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0,3)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history[:,2:4])\n",
        "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "kBKTlKYvZke6",
        "outputId": "aac0993a-2083-4cb0-edf7-5d085a4b3260"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4) Output the mean accuracy for the whole testing dataset.\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "#         images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "#         images = images.view(images.size(0), -1)\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "#         images = images.view(images.size(0), -1)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVxDctO9aYYx",
        "outputId": "eaadc7a2-05c0-4564-ec67-a2358423c438"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 86 %\n",
            "Accuracy for class: T-shirt/top is 84.7 %\n",
            "Accuracy for class: Trouser is 97.4 %\n",
            "Accuracy for class: Pullover is 90.0 %\n",
            "Accuracy for class: Dress is 88.6 %\n",
            "Accuracy for class: Coat  is 77.2 %\n",
            "Accuracy for class: Sandal is 97.3 %\n",
            "Accuracy for class: Shirt is 41.0 %\n",
            "Accuracy for class: Sneaker is 92.9 %\n",
            "Accuracy for class: Bag   is 95.7 %\n",
            "Accuracy for class: Ankle Boot is 96.6 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Zjsjxq8zuq"
      },
      "source": [
        "c) Replace your defined CNN in b) with a pre-trained model. Then, proceed with a transfer learning and finetune the model for the Fashion MNIST dataset. **[10 marks]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "D4joDd5u8zur",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "1d35299a47df47f585f7bb233d17fefe",
            "d0018f06aa094dec9eb23e7ba212cf38",
            "abc1ef82e7ac485ebeb101351b772c3b",
            "169be653eaf043f4bb9ca999d5abed03",
            "3786452fa2aa4e4e82fe1848c06e2d36",
            "ab3e3687293c4a9a9a6525b82f32faeb",
            "1025fe6adefd4294a61517e4cc9628b4",
            "d75c9b232ad84c27bb6c940e0a8438ac",
            "3b4a53d10c8b454e857638a82c375721",
            "b3126ec1ae8c49529abd153a035a2f01",
            "20c88a8017b44ea6890744c20e74ff90"
          ]
        },
        "outputId": "3f5e3337-a4c6-41dd-b4c7-b914679e1108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d35299a47df47f585f7bb233d17fefe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Define Pre-trained Model: Resnet50\n",
        "\n",
        "class FashionResnet(nn.Module):\n",
        "  def __init__(self, in_channels=1):\n",
        "    super(FashionResnet, self).__init__()\n",
        "\n",
        "    self.model = models.resnet50(pretrained=True)\n",
        "    self.model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Transfer learning and finetune model to fit the Fashion MNIST dataset.\n",
        "    num_ftrs = self.model.fc.in_features\n",
        "    self.model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "\n",
        "my_resnet = FashionResnet()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. LOSS AND OPTIMIZER\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "optimizer_my_resnet = optim.Adam(my_resnet.parameters(), lr=0.001)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "my_resnet.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYQzroaFdvn7",
        "outputId": "f93f2fc3-7535-4189-af68-0776f7ec9681"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionResnet(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(my_resnet, criterion2, optimizer_my_resnet, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaUrjcCWfH7z",
        "outputId": "5b584ed9-bec9-4abc-c5d1-91cf596d79a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10\n",
            "Epoch : 000, Training: Loss: 0.4686, Accuracy: 83.2283%, \n",
            "\t\tValidation : Loss : 0.3727, Accuracy: 86.8500%, Time: 52.0787s\n",
            "Epoch: 2/10\n",
            "Epoch : 001, Training: Loss: 0.4085, Accuracy: 85.9017%, \n",
            "\t\tValidation : Loss : 0.5364, Accuracy: 80.6300%, Time: 51.3283s\n",
            "Epoch: 3/10\n",
            "Epoch : 002, Training: Loss: 0.3517, Accuracy: 87.2683%, \n",
            "\t\tValidation : Loss : 0.3132, Accuracy: 88.4300%, Time: 63.0526s\n",
            "Epoch: 4/10\n",
            "Epoch : 003, Training: Loss: 0.2882, Accuracy: 89.6183%, \n",
            "\t\tValidation : Loss : 0.2996, Accuracy: 88.9000%, Time: 54.3306s\n",
            "Epoch: 5/10\n",
            "Epoch : 004, Training: Loss: 0.2607, Accuracy: 90.3800%, \n",
            "\t\tValidation : Loss : 0.2927, Accuracy: 89.5300%, Time: 53.5711s\n",
            "Epoch: 6/10\n",
            "Epoch : 005, Training: Loss: 0.3040, Accuracy: 89.0533%, \n",
            "\t\tValidation : Loss : 0.2838, Accuracy: 89.4700%, Time: 51.0870s\n",
            "Epoch: 7/10\n",
            "Epoch : 006, Training: Loss: 0.2441, Accuracy: 90.9567%, \n",
            "\t\tValidation : Loss : 0.2727, Accuracy: 90.0700%, Time: 51.7696s\n",
            "Epoch: 8/10\n",
            "Epoch : 007, Training: Loss: 0.2386, Accuracy: 91.1367%, \n",
            "\t\tValidation : Loss : 0.2512, Accuracy: 90.9500%, Time: 50.9014s\n",
            "Epoch: 9/10\n",
            "Epoch : 008, Training: Loss: 0.2264, Accuracy: 91.5800%, \n",
            "\t\tValidation : Loss : 0.2584, Accuracy: 90.9100%, Time: 51.6887s\n",
            "Epoch: 10/10\n",
            "Epoch : 009, Training: Loss: 0.2041, Accuracy: 92.5017%, \n",
            "\t\tValidation : Loss : 0.2553, Accuracy: 91.0000%, Time: 50.9807s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot\n",
        "history = np.array(history)\n",
        "plt.plot(history[:,0:2])\n",
        "plt.legend(['Tr Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0,3)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history[:,2:4])\n",
        "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "KUtkKd3Ek2k9",
        "outputId": "70581984-efa3-4adb-fb20-52e92026477d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU9Z3/8ddnMpNMbkAgiAq00K2o9QKWFN1irUr9/XRlYVsVxLX9WVvdXrTV2v2ttd3W3h6/rvVWu64VrdfFeNt1l/pTqXdr1dagFhVFKdASpAghBMIkmczMZ/84kzCJSRgwkyE57+fjMY85t5z5ZCDf95zvmfM95u6IiEh4RYpdgIiIFJeCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQq5gQWBmt5jZu2b2Wj/rzcyuM7PVZrbCzD5aqFpERKR/hTwiuA04eYD1pwAHZR/nAzcUsBYREelHwYLA3Z8Btg6wyXzgDg+8AIwxswMKVY+IiPQtWsTXngisz5lvzC7b2HtDMzuf4KiBysrKmYcccsiQFCgiMlIsX758i7uP72tdMYMgb+6+GFgMUFdX5w0NDUWuSERkeDGzP/W3rpjfGtoATM6Zn5RdJiIiQ6iYQbAU+Fz220PHAC3u/p5uIRERKayCdQ2ZWT1wPFBrZo3A94AYgLv/AngI+BtgNZAAPl+oWkREpH8FCwJ3X7Sb9Q58tVCvLyIi+dGVxSIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiIiEnIJARCTkFAQiIiGnIBAR2cclUxmaWjvY2ZEqyP6HxTDUIiLDVSqdYUd7ih3tKba3d7K9vbN7fkf3dCfb21Ls6OjMbrdr3fa2TjpSGQD+32eOYNGsDwx6jQoCEZFe3J1UxkmmMnSkMuzsSPXfgPd47tmA72hP0daZ3u3rlcdKqI5HqY5HGVUeY3R5jEk15YyKR6mOx7qfZ36wpiC/r4JARIaUu5NxSGecjDvpjJN2J5PJnYaMO6m005FK05HKkExn6OgMnoMGOk0ylelurJNd2/S3rmt5uq/lXfPp7n245/f7lEUjOY110JAfMDpOdVks27jHGFUePHc39vEYo7LzVfEosZLi9tIrCERCrC2ZZsO2NhqbE2zY1saG5jYam9vYujNJKpMhk4F0trHubrRzpt1z1mcb8XS2Ee+5zMHTxDMJqjxBlbVRTfA8irYe89UkqLY2qmijlE4AHOt+dsCAMoyy7uU9tzEzIgZmESIRI2KGRYyIRYJps+7lkYgRKTUi8ciu+Uh2OjsfjRixEqM0AtESiEUgFjFiEYjg4EHXDd417dCRgfacec/krKfXfO/1OfN4drnDcd+Ewz8z6P8PFAQyorl796H9zo40O5OpYDqZzi4LHu2pDKPiMcZVlVJbVcq4yjLGVZVSVRbFzIr9a+y17e2dbGjuauCzjf22oLHf0NxG085kj+2jEePAMeXUVpUSjUSIRCBmRjlJqkhQ6W1UeIJKdlLpCco9ETxnEpT7TsozwSOeSRBPtxLPJChLt1KWTlCWSey23gwROmNVdEarSEUryZSUEQHMgkcEDxpxwCxo+ndNW/cyg12NaPc0dDeqA01nHNK5y7M7tEgwYZFsQb3mu6fz2LZrPhIBiw6wfa/p+Kh8/+n3iIJA9imZjLMzmSKRTNPakSLRETwHjXfQmCeSqWBd9zYpWrPLcxv5rm3SmTyP8ftQGo1QW1nK2JxwqK0qY1xlKeO6n3dNx2Mlg/huDMzdaU50smHrTt7Z0sy7W5vZ0ryNpuYWtm1vYceO7aSTbZTTQTlJ4tZBdaSTGeUZTopnGFeTpmZCilHRFNWRTioiScq8A+tsg+ROaNsBHS3QsWPXp9iBlFZB2Sgoqw4arLL9g+myUcEjPipnvmubUT3mI7EKyswoK/zbJzkUBDJkEskUa7fsZM3mndnnVtY2JdiWSAaf1jvyO7HWJR6LUFUWpaI0SmVZlFEx54B4mprqFKNLkoyOpqiOJqku6aTKklRGklRaknI6iGcfpd5BaaadaKadzlSG9lSG9lRwFNHeuWu+vSND+84MbRsytHVmSGVgJ9CKsS6nSyJaEiEeixKPlVAWixIvLaG8NEo8FqW8NJqdLqG8LEp5LEokkvNpDwMcOtugsw3vbKOjrZX2RCud7TtJdSTwZAJLtVGSbqc00045SY6wJEf09yaV9rEsmX3EKiBWHjxH47umSyuhar9dDXR3oz1Ao15WDZGhC0EZXAoCGVTpjPPOtjb+uLmVNZt3sm7zdtZvbmbDlhaat++gzDopI3hMqo4wa1QJtTVpqiKdVJd0UGmdVEaCxrrCgk+oZd5OmXcQy7QRTbdTkmmnJJUIPrl2tkEyAS0JyHTuecFdjWG0nKgZ5bl9sr2fSxwijpcF8xl3PJPB3bOPoE/XMx70Dbft+tncHu6gyXccJ5Pt7siVpJQ2ykh4jISX0Z6db/NSUiWjiZQeQLS8gli8knhFFRWV1VRVVTN61GjiFZVYrCKnkS/f1cDnPkfj2fARURCE1/Z3oOmPkOqAVDukO3ZNpzpyHtn5dO66dpId7bS3JUi2J0gl20h3Bssj6Q4q6GQmKT5OklLL+YQf71VDEtgyQI0lpdmGK9t4lWany7KfWHOXxcohVtn/slh58Ek3d1k0HvTR7qGu5jPfz7+ZjLO9vZMtrUmaWjto2pkMHq0dNLUmadrZEazb0U4imWbC6HIm1ZQzsaacSWPKmVRTwcSacg4dU05lmf5kZfDpf1XYNK+D31wFr9wFmd1fpeiRGOlIKZ0Wo8NjtHmMnekSEpkoHQTLOi1OSWkNpeUVxMsrqKyooLqqipKqKmLl5VgsHjS60TIoKQueo13LSnt9Ws2ZLhkZ/z0jEWNMRSljKkr58H5VxS5H5D1Gxl+a7F7zn+A3VwYBYCVQ9wU4dC4ejbOl3WjcnmZdS5o121L8cWuKt5s6Wbutk5Tv+sQ8vrqMD42v5EPjq/hQbWX39KSa8qJ/D1pE9l54gsA9VH2i7s729hQt76wm/sK11K6+H7cIKyacxq9rzmRN0ygaf9XG2i1bSSR3dd+Ux0qYWlvJwZNrOOWobKM/vpIptZWMiseK+BuJSKGEJwhefwBe+DeY+Xk47NNBP/Iwk0pn2JpIsmVHV79y0Me8Ofu8Jee5rHUD59sDnFHyNBmMO9InckNqHpvWjqVmU4raqp0cMKacj00Zy1+N39XgT6iOE4mEJzBFJExBEIlC2zb476/AI9+C6Qth5jkw4bCiltWWTLOltSP7CE4gdk3nNuxNO5M0J5J9XvYeK7Hgu+1VpRwc38a3MvdydPIhwFg3ZQGbp3+FWftN4W+qSqmpLFU3joj0YJ7vgBr7iLq6Om9oaNi7H3aHP/0Wlt8GK/8b0kmY9LGCHiVkMs6GbW2s+ssOVm3awVubdvDnrYnuBj63WyZXVVk0uMK1qiznOZiuzU53Xdw0Kh7FWhqDk8Av/3vQBfbRz8Gx34DREwf9dxKR4cfMlrt7XZ/rQhUEuXY2wR/qg1BoehvKRr+vowR3Z/OODlZt2sGqvwQN/qpNrby9aUePxv7A0XGm1Fb2aMzH5zTqXc95X6HaFQAv3RnMf/Rz8IlvwOhJe/w7iMjIpSAYyF4cJbQkOoMGf9MO3sr5pL8tseuCpnGVpUybUM3B+1dnn6s4aEL14J1wbWmE31wNL90RzH/0c3DsxTBm8uDsX0RGFAVBvnodJXjZKJr+6tMsr53Pi4kDuhv8Tds7un+kuizKtK7GfkJV93RtVYFGS2nZAM9mA8AdPvrZoAtIASAiAxgoCMJzsngAyVSGNVtaWfWXdt7a8SlWVR9NeesLzEk8xCmvL+F/2+3s5wdRWXUqB37oFD50wFSm7V/NwROqOWB0fGhGp2zZAM9eAy/dHgTAUWcHXUBjBv9uRSISLqEKgnTG+fPWRE4fftC1s3bLTlLZESpLIsaHaiuZ9sHZ/HnCyTw7ppMZWx9hxpt3cVTTtbD2Vhi1EMacA2P2K3zR29/JdgHdHowAedTZ8IlLFAAiMmhC0zV062/X8pOH3+y+9yfAB8ZWdPffd/XnT62tpCzax4lad/jTc7D81qH5xtH2d4IjgOW3BQEw4++DAKj54OC+joiEgs4RAM+t3sITb77b3aXz4f2q9n4Ar8TW4FxCw62D8o2jHrZvzAmAtAJARAaFgqBQBvMoYftG+O21Qbh4GmaclQ2AKQUrX0TCQ0EwFPb2KGHHX4IjgIZbg9FAuwJg7NQhK11ERj4FwVDK9yhhx1/g2WuD7dKdMGMRfOKbCgARKYiiBYGZnQz8jOAeHje7+096rf8AcDswJrvNpe7+0ED73OeDIFdfRwlHLgjGPeoKgOmL4DgFgIgUVlGCwMxKgLeAk4BG4EVgkbuvzNlmMfCyu99gZh8BHnL3KQPtd1gFQZfeRwmZdDYALoGxHyp2dSISAsW6oGwWsNrd12SLuBuYD6zM2caBUdnp0cA7BayneMxgyuzgccoVwZFA9YRiVyUiAhQ2CCYC63PmG4Gje21zOfBrM7sQqAQ+1deOzOx84HyAD3xgmF9IVTG22BWIiPRQ7IHpFwG3ufsk4G+AO83sPTW5+2J3r3P3uvHjxw95kSIiI1khg2ADkDsS2qTsslxfAO4FcPfngThQW8CaRESkl0IGwYvAQWY21cxKgTOBpb22+TMwB8DMDiUIgs0FrElERHopWBC4ewq4AFgGvAHc6+6vm9kPzGxedrNLgPPM7A9APXCOD7cLG0REhrmCjj6avSbgoV7LvpszvRKYXcgaRERkYMU+WSwiIkWmIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQUxCIiIScgkBEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiIiEnIJARCTkFAQiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQm5ggaBmZ1sZqvMbLWZXdrPNgvMbKWZvW5mdxWyHhERea9ooXZsZiXA9cBJQCPwopktdfeVOdscBHwLmO3uzWa2X6HqERGRvhXyiGAWsNrd17h7ErgbmN9rm/OA6929GcDd3y1gPSIi0odCBsFEYH3OfGN2Wa5pwDQz+62ZvWBmJ/e1IzM738wazKxh8+bNBSpXRCScin2yOAocBBwPLAJuMrMxvTdy98XuXufudePHjx/iEkVERrbdBoGZ/a2Z7U1gbAAm58xPyi7L1QgsdfdOd18LvEUQDCIiMkTyaeAXAm+b2RVmdsge7PtF4CAzm2pmpcCZwNJe2/wXwdEAZlZL0FW0Zg9eQ0RE3qfdBoG7nw0cBfwRuM3Mns/22Vfv5udSwAXAMuAN4F53f93MfmBm87KbLQOazGwl8CTwj+7e9D5+HxER2UPm7vltaDYO+CxwEUHD/mHgOnf/eeHKe6+6ujpvaGgYypcUERn2zGy5u9f1tS6fcwTzzOwB4CkgBsxy91OA6cAlg1moiIgMvXwuKDsNuMbdn8ld6O4JM/tCYcoSEZGhkk8QXA5s7Joxs3Jggruvc/fHC1WYiIgMjXy+NXQfkMmZT2eXiYjICJBPEESzQ0QAkJ0uLVxJIiIylPIJgs05X/fEzOYDWwpXkoiIDKV8zhF8CVhiZv8KGMH4QZ8raFUiIjJkdhsE7v5H4Bgzq8rOtxa8KhERGTJ53Y/AzE4FDgPiZgaAu/+ggHWJiMgQyeeCsl8QjDd0IUHX0BnABwtcl4iIDJF8ThZ/3N0/BzS7+/eBvyYYHE5EREaAfIKgPfucMLMDgU7ggMKVJCIiQymfcwS/yt4s5qfAS4ADNxW0KhERGTIDBkH2hjSPu/s24D/M7EEg7u4tQ1KdiIgU3IBdQ+6eAa7Pme9QCIiIjCz5nCN43MxOs67vjYqIyIiSTxD8A8Egcx1mtt3MdpjZ9gLXJSIiQySfK4sHvCWliIgMb7sNAjM7rq/lvW9UIyIiw1M+Xx/9x5zpODALWA6cWJCKRERkSOXTNfS3ufNmNhm4tmAViYjIkMrnZHFvjcChg12IiIgURz7nCH5OcDUxBMExg+AKYxERGQHyOUfQkDOdAurd/bcFqkdERIZYPkFwP9Du7mkAMysxswp3TxS2NBERGQp5XVkMlOfMlwOPFaYcEREZavkEQTz39pTZ6YrClSQiIkMpnyDYaWYf7Zoxs5lAW+FKEhGRoZTPOYKLgPvM7B2CW1XuT3DrShERGQHyuaDsRTM7BDg4u2iVu3cWtiwRERkq+dy8/qtApbu/5u6vAVVm9pXClyYiIkMhn3ME52XvUAaAuzcD5xWuJBERGUr5BEFJ7k1pzKwEKC1cSSIiMpTyOVn8CHCPmd2Ynf8H4OHClSQiIkMpnyD4J+B84EvZ+RUE3xwSEZERYLddQ9kb2P8OWEdwL4ITgTfy2bmZnWxmq8xstZldOsB2p5mZm1ldfmWLiMhg6feIwMymAYuyjy3APQDufkI+O86eS7geOIlg6OoXzWypu6/stV018HWCsBERkSE20BHBmwSf/ue6+7Hu/nMgvQf7ngWsdvc17p4E7gbm97HdD4F/Adr3YN8iIjJIBgqCzwAbgSfN7CYzm0NwZXG+JgLrc+Ybs8u6ZYeumOzu/3+gHZnZ+WbWYGYNmzdv3oMSRERkd/oNAnf/L3c/EzgEeJJgqIn9zOwGM/tf7/eFzSwCXA1csrtt3X2xu9e5e9348ePf70uLiEiOfE4W73T3u7L3Lp4EvEzwTaLd2QBMzpmflF3WpRo4HHjKzNYBxwBLdcJYRGRo7dE9i929OfvpfE4em78IHGRmU82sFDgTWJqzrxZ3r3X3Ke4+BXgBmOfuDX3vTkRECmFvbl6fF3dPARcAywi+bnqvu79uZj8ws3mFel0REdkz+VxQttfc/SHgoV7LvtvPtscXshYREelbwY4IRERkeFAQiIiEnIJARCTkFAQiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQUxCIiIScgkBEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiIiEnIJARCTkFAQiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhFxBg8DMTjazVWa22swu7WP9N8xspZmtMLPHzeyDhaxHRETeq2BBYGYlwPXAKcBHgEVm9pFem70M1Ln7kcD9wBWFqkdERPpWyCOCWcBqd1/j7kngbmB+7gbu/qS7J7KzLwCTCliPiIj0oZBBMBFYnzPfmF3Wny8AD/e1wszON7MGM2vYvHnzIJYoIiL7xMliMzsbqAN+2td6d1/s7nXuXjd+/PihLU5EZISLFnDfG4DJOfOTsst6MLNPAd8GPunuHQWsR0RE+lDII4IXgYPMbKqZlQJnAktzNzCzo4AbgXnu/m4BaxERkX4ULAjcPQVcACwD3gDudffXzewHZjYvu9lPgSrgPjN7xcyW9rM7EREpkEJ2DeHuDwEP9Vr23ZzpTxXy9UVEZPcKGgRDpbOzk8bGRtrb24tdSujF43EmTZpELBYrdikikqcREQSNjY1UV1czZcoUzKzY5YSWu9PU1ERjYyNTp04tdjkikqd94uuj71d7ezvjxo1TCBSZmTFu3DgdmYkMMyMiCACFwD5C/w4iw8+ICQIREdk7CoJB0NTUxIwZM5gxYwb7778/EydO7J5PJpP9/txFF13ExIkTyWQyQ1itiEhPI+JkcbGNGzeOV155BYDLL7+cqqoqvvnNb3avT6VSRKM93+pMJsMDDzzA5MmTefrppznhhBMKUltfry0ikmvEtRDf/9XrrHxn+6Du8yMHjuJ7f3vYHv3MOeecQzwe5+WXX2b27NlcffXVPdY/9dRTHHbYYSxcuJD6+vruINi0aRNf+tKXWLNmDQA33HADH//4x7njjju48sorMTOOPPJI7rzzTs455xzmzp3L6aefDkBVVRWtra089dRT/PM//zM1NTW8+eabvPXWW/zd3/0d69evp729na9//eucf/75ADzyyCNcdtllpNNpamtrefTRRzn44IN57rnnGD9+PJlMhmnTpvH888+jcZ5ERqYRFwT7ksbGRp577jlKSkres66+vp5FixYxf/58LrvsMjo7O4nFYnzta1/jk5/8JA888ADpdJrW1lZef/11fvSjH/Hcc89RW1vL1q1bd/vaL730Eq+99lr31zhvueUWxo4dS1tbGx/72Mc47bTTyGQynHfeeTzzzDNMnTqVrVu3EolEOPvss1myZAkXXXQRjz32GNOnT1cIiIxgIy4I9vSTeyGdccYZfYZAMpnkoYce4uqrr6a6upqjjz6aZcuWMXfuXJ544gnuuOMOAEpKShg9ejR33HEHZ5xxBrW1tQCMHTt2t689a9asHt/lv+6663jggQcAWL9+PW+//TabN2/muOOO696ua7/nnnsu8+fP56KLLuKWW27h85///Pt7I0RknzbigmBfUllZ2efyZcuWsW3bNo444ggAEokE5eXlzJ07d4/2H41Gu080ZzKZHiemc1/7qaee4rHHHuP555+noqKC448/fsDv+k+ePJkJEybwxBNP8Pvf/54lS5bsUV0iMrzoW0NFUF9fz80338y6detYt24da9eu5dFHHyWRSDBnzhxuuOEGANLpNC0tLZx44oncd999NDU1AXR3DU2ZMoXly5cDsHTpUjo7O/t8vZaWFmpqaqioqODNN9/khRdeAOCYY47hmWeeYe3atT32C/DFL36Rs88+u9+jGhEZORQEQyyRSPDII49w6qmndi+rrKzk2GOP5Ve/+hU/+9nPePLJJzniiCOYOXMmK1eu5LDDDuPb3/42n/zkJ5k+fTrf+MY3ADjvvPN4+umnmT59Os8//3y/RyAnn3wyqVSKQw89lEsvvZRjjjkGgPHjx7N48WI+85nPMH36dBYuXNj9M/PmzaO1tVXdQiIhYO5e7Br2SF1dnTc0NPRY9sYbb3DooYcWqaKRqaGhgYsvvpjf/OY3e/yz+vcQ2feY2XJ3r+trnc4RyHv85Cc/4YYbbtC5AZGQUNeQvMell17Kn/70J4499thilyIiQ0BBICIScgoCEZGQUxCIiIScgkBEJOQUBIPghBNOYNmyZT2WXXvttXz5y1/u92eOP/54en8NtsuWLVuIxWL84he/GNQ6RUT6oiAYBIsWLeLuu+/usezuu+9m0aJFe7W/++67j2OOOYb6+vrBKK9fqVSqoPsXkeFh5F1H8PCl8JdXB3ef+x8Bp/yk39Wnn3463/nOd0gmk5SWlrJu3TreeecdPvGJT/DlL3+ZF198kba2Nk4//XS+//3v7/bl6uvrueqqqzjrrLNobGxk0qRJAH0ORd3XsNUHHnggc+fO5bXXXgPgyiuvpLW1lcsvv5zjjz+eGTNm8Oyzz7Jo0SKmTZvGj370I5LJJOPGjWPJkiVMmDCB1tZWLrzwQhoaGjAzvve979HS0sKKFSu49tprAbjppptYuXIl11xzzft9h0WkiEZeEBTB2LFjmTVrFg8//DDz58/n7rvvZsGCBZgZP/7xjxk7dizpdJo5c+awYsUKjjzyyH73tX79ejZu3MisWbNYsGAB99xzD5dcckm/Q1H3NWx1c3PzgPUmk8nubqnm5mZeeOEFzIybb76ZK664gquuuoof/vCHjB49mldffbV7u1gsxo9//GN++tOfEovFuPXWW7nxxhsH6V0UkWIZeUEwwCf3QurqHuoKgl/+8pcA3HvvvSxevJhUKsXGjRtZuXLlgEFwzz33sGDBAgDOPPNMzj33XC655BKeeOKJPoei7mvY6t0FQe6YQo2NjSxcuJCNGzeSTCa7h6R+7LHHenR31dTUAHDiiSfy4IMPcuihh9LZ2dk9gqqIDF86RzBI5s+fz+OPP85LL71EIpFg5syZrF27liuvvJLHH3+cFStWcOqppw44/DME3UK33XYbU6ZMYd68eaxYsYK33357j2rJHZ4aeM9r5g5Od+GFF3LBBRfw6quvcuONN+62vi9+8Yvcdttt3HrrrRqQTmSEUBAMkqqqKk444QTOPffc7pPE27dvp7KyktGjR7Np0yYefvjhAffx1ltv0drayoYNG7qHqP7Wt75FfX19v0NR9zVs9YQJE3j33Xdpamqio6ODBx98sN/XbGlpYeLEiQDcfvvt3ctPOukkrr/++u75rqOMo48+mvXr13PXXXft9clwEdm3KAgG0aJFi/jDH/7Q3UBOnz6do446ikMOOYSzzjqL2bNnD/jz9fX1fPrTn+6x7LTTTqO+vr7foaj7GrY6Fovx3e9+l1mzZnHSSSdxyCGH9Pual19+OWeccQYzZ87s7nYC+M53vkNzczOHH34406dP58knn+xet2DBAmbPnt3dXSQiw5uGoZY9NnfuXC6++GLmzJnT53r9e4jsewYahlpHBJK3bdu2MW3aNMrLy/sNAREZfkbet4akYMaMGcNbb71V7DJEZJCNmCOC4dbFNVLp30Fk+BkRQRCPx2lqalIjVGTuTlNTE/F4vNiliMgeGBFdQ5MmTaKxsZHNmzcXu5TQi8fj3UNiiMjwMCKCIBaLdV8RKyIie6agXUNmdrKZrTKz1WZ2aR/ry8zsnuz635nZlELWIyIi71WwIDCzEuB64BTgI8AiM/tIr82+ADS7+4eBa4B/KVQ9IiLSt0IeEcwCVrv7GndPAncD83ttMx/oGtfgfmCOmVkBaxIRkV4KeY5gIrA+Z74ROLq/bdw9ZWYtwDhgS+5GZnY+cH52ttXMVu1lTbW99x1yej960vuxi96LnkbC+/HB/lYMi5PF7r4YWPx+92NmDf1dYh1Gej960vuxi96Lnkb6+1HIrqENwOSc+UnZZX1uY2ZRYDTQVMCaRESkl0IGwYvAQWY21cxKgTOBpb22WQr8n+z06cATrqvCRESGVMG6hrJ9/hcAy4AS4BZ3f93MfgA0uPtS4JfAnWa2GthKEBaF9L67l0PGHwwAAAUfSURBVEYYvR896f3YRe9FTyP6/Rh2w1CLiMjgGhFjDYmIyN5TEIiIhFxogmB3w12EhZlNNrMnzWylmb1uZl8vdk37AjMrMbOXzaz/GzyHhJmNMbP7zexNM3vDzP662DUVi5ldnP07ec3M6s1sRA6tG4ogyHO4i7BIAZe4+0eAY4Cvhvi9yPV14I1iF7GP+BnwiLsfAkwnpO+LmU0EvgbUufvhBF96KfQXWooiFEFAfsNdhIK7b3T3l7LTOwj+yCcWt6riMrNJwKnAzcWupdjMbDRwHME3+nD3pLtvK25VRRUFyrPXOVUA7xS5noIISxD0NdxFqBs/gOxor0cBvytuJUV3LfB/gUyxC9kHTAU2A7dmu8puNrPKYhdVDO6+AbgS+DOwEWhx918Xt6rCCEsQSC9mVgX8B3CRu28vdj3FYmZzgXfdfXmxa9lHRIGPAje4+1HATiCU59TMrIag52AqcCBQaWZnF7eqwghLEOQz3EVomFmMIASWuPt/FrueIpsNzDOzdQRdhiea2b8Xt6SiagQa3b3rKPF+gmAIo08Ba919s7t3Av8JfLzINRVEWIIgn+EuQiE7zPcvgTfc/epi11Ns7v4td5/k7lMI/l884e4j8lNfPtz9L8B6Mzs4u2gOsLKIJRXTn4FjzKwi+3czhxF64nxYjD76fvU33EWRyyqW2cBngVfN7JXsssvc/aEi1iT7lguBJdkPTWuAzxe5nqJw99+Z2f3ASwTftnuZETrUhIaYEBEJubB0DYmISD8UBCIiIacgEBEJOQWBiEjIKQhEREJOQSDDmpmlzeyVnMegXQVrZlPM7LU8trvczBJmtl/OstahrEHk/QjFdQQyorW5+4xiFwFsAS4B/qnYheQys6i7p4pdh+zbdEQgI5KZrTOzK8zsVTP7vZl9OLt8ipk9YWYrzOxxM/tAdvkEM3vAzP6QfXQNJVBiZjdlx6T/tZmV9/OStwALzWxsrzp6fKI3s2+a2eXZ6afM7Boza8iO+/8xM/tPM3vbzH6Us5uomS3JbnO/mVVkf36mmT1tZsvNbJmZHZCz32vNrIFgeG2RASkIZLgr79U1tDBnXYu7HwH8K8EIowA/B2539yOBJcB12eXXAU+7+3SCsXW6rjw/CLje3Q8DtgGn9VNHK0EY7GnDm3T3OuAXwH8DXwUOB84xs3HZbQ4G/s3dDwW2A1/Jjhf1c+B0d5+Zfe0f5+y31N3r3P2qPaxHQkhdQzLcDdQ1VJ/zfE12+q+Bz2Sn7wSuyE6fCHwOwN3TQEt29Mm17t41FMdyYMoAtVwHvGJmV+5B/V1jXr0KvO7uGwHMbA3BQInbgPXu/tvsdv9OcLOURwgC49FgGBxKCIZK7nLPHtQgIacgkJHM+5neEx0502mgv64h3H2bmd1F8Km+S4qeR969b3XYtf9Mr9fKsOvvs3ftDhhBcPR3G8md/dUp0pu6hmQkW5jz/Hx2+jl23W7w74HfZKcfB74M3fcvHr2Xr3k18A/sasQ3AfuZ2TgzKwPm7sU+P5Bz3+CzgGeBVcD4ruVmFjOzw/ayZgk5BYEMd73PEfwkZ12Nma0g6Le/OLvsQuDz2eWfZVef/teBE8zsVYIuoL26j7O7bwEeAMqy853AD4DfA48Cb+7FblcR3Fv6DaCG4KYxSeB04F/M7A/AK4zQsfKl8DT6qIxI2RvN1GUbZhEZgI4IRERCTkcEIiIhpyMCEZGQUxCIiIScgkBEJOQUBCIiIacgEBEJuf8ByPt0aqS/+28AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "#         images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "#         images = images.view(images.size(0), -1)\n",
        "        outputs = my_resnet(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "#         images = images.view(images.size(0), -1)\n",
        "        outputs = my_resnet(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGEPKb9dk-Q3",
        "outputId": "1df8c35e-68ee-4615-caee-c3c55bdc3268"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 91 %\n",
            "Accuracy for class: T-shirt/top is 92.8 %\n",
            "Accuracy for class: Trouser is 97.1 %\n",
            "Accuracy for class: Pullover is 79.2 %\n",
            "Accuracy for class: Dress is 93.0 %\n",
            "Accuracy for class: Coat  is 90.8 %\n",
            "Accuracy for class: Sandal is 98.5 %\n",
            "Accuracy for class: Shirt is 67.2 %\n",
            "Accuracy for class: Sneaker is 97.0 %\n",
            "Accuracy for class: Bag   is 98.6 %\n",
            "Accuracy for class: Ankle Boot is 95.8 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6uCpzFC8zur"
      },
      "source": [
        "d) Using model-centric methods, propose two (2) strategies that can be used to increase the accuracy of the model on the testing dataset. **[5 marks]**\n",
        "\n",
        "\n",
        "<span style=\"color:blue\">\n",
        "    Two model-centric techniques that I propose are:\n",
        "    <br>1. Batch Normalization </br>\n",
        "    <br>2. Dropout</br> </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FIMfUfz8zur"
      },
      "source": [
        "e) Next, implement the two proposed model-centric techniques for the same problem as in the previous question. **[15 marks]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9UIGCk5K8zus"
      },
      "outputs": [],
      "source": [
        "#e) Model-centric Techniques\n",
        "\n",
        "class CNN2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3, padding=2)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.conv5 = nn.Conv2d(512, 512, 1)\n",
        "        self.dp = nn.Dropout(0.4)\n",
        "        self.fc6 = nn.Linear(512 * 1 * 1, 4096)\n",
        "        self.fc7 = nn.Linear(4096, 1000)\n",
        "        self.fc8 = nn.Linear(1000, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(self.pool(self.relu(self.conv1(x))))\n",
        "        x = self.bn2(self.pool(self.relu(self.conv2(x))))\n",
        "        x = self.bn3(self.pool(self.relu(self.conv3(x))))\n",
        "        x = self.bn4(self.pool(self.relu(self.conv4(x))))\n",
        "        x = self.bn4(self.pool(self.relu(self.conv5(x))))\n",
        "        x = x.view(-1, 512 * 1 * 1)\n",
        "        x = self.dp(self.relu(self.fc6(x)))\n",
        "        x = self.dp(self.relu(self.fc7(x)))\n",
        "        x = self.fc8(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = CNN2()\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion3 = nn.CrossEntropyLoss()\n",
        "optimizer_model2 = optim.Adam(model2.parameters(), lr=0.001)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model2.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7gyKZLvHnEN",
        "outputId": "d63a35a7-9fcb-4191-85e7-14552ca1a83a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN2(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (dp): Dropout(p=0.4, inplace=False)\n",
              "  (fc6): Linear(in_features=512, out_features=4096, bias=True)\n",
              "  (fc7): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (fc8): Linear(in_features=1000, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(model2, criterion3, optimizer_model2, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07J_eauQHwYO",
        "outputId": "4d28b964-a7f5-4377-d0cb-7d930a7d906a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10\n",
            "Epoch : 000, Training: Loss: 0.4310, Accuracy: 85.0617%, \n",
            "\t\tValidation : Loss : 0.3445, Accuracy: 87.6400%, Time: 22.0256s\n",
            "Epoch: 2/10\n",
            "Epoch : 001, Training: Loss: 0.3370, Accuracy: 88.9933%, \n",
            "\t\tValidation : Loss : 0.2974, Accuracy: 89.2800%, Time: 21.8946s\n",
            "Epoch: 3/10\n",
            "Epoch : 002, Training: Loss: 0.2523, Accuracy: 91.3650%, \n",
            "\t\tValidation : Loss : 0.2939, Accuracy: 90.3000%, Time: 21.7942s\n",
            "Epoch: 4/10\n",
            "Epoch : 003, Training: Loss: 0.2248, Accuracy: 92.2033%, \n",
            "\t\tValidation : Loss : 0.2674, Accuracy: 90.7900%, Time: 21.8056s\n",
            "Epoch: 5/10\n",
            "Epoch : 004, Training: Loss: 0.2221, Accuracy: 92.5200%, \n",
            "\t\tValidation : Loss : 0.2717, Accuracy: 91.2700%, Time: 22.3439s\n",
            "Epoch: 6/10\n",
            "Epoch : 005, Training: Loss: 0.1783, Accuracy: 93.8283%, \n",
            "\t\tValidation : Loss : 0.2360, Accuracy: 92.2100%, Time: 21.7757s\n",
            "Epoch: 7/10\n",
            "Epoch : 006, Training: Loss: 0.1556, Accuracy: 94.5817%, \n",
            "\t\tValidation : Loss : 0.2834, Accuracy: 91.4000%, Time: 21.7001s\n",
            "Epoch: 8/10\n",
            "Epoch : 007, Training: Loss: 0.1494, Accuracy: 94.8433%, \n",
            "\t\tValidation : Loss : 0.2842, Accuracy: 92.2200%, Time: 21.7432s\n",
            "Epoch: 9/10\n",
            "Epoch : 008, Training: Loss: 0.1292, Accuracy: 95.5783%, \n",
            "\t\tValidation : Loss : 0.3043, Accuracy: 90.6300%, Time: 21.9324s\n",
            "Epoch: 10/10\n",
            "Epoch : 009, Training: Loss: 0.1144, Accuracy: 95.9967%, \n",
            "\t\tValidation : Loss : 0.3134, Accuracy: 92.5400%, Time: 21.7660s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzPPxsCX8zus"
      },
      "source": [
        "f) Do you see any accuracy improvement? Whether it is a \"yes\" or \"no\", discuss the possible reasons contributing to the accuracy improvement/ unimprovement. **[5 marks]**\n",
        "\n",
        "<span style=\"color:blue\">\n",
        "    Yes, the accuracy has increased about 2%.\n",
        "    <br>Batch normalization sets the learning rates high which speeds up the training process. The mean and variance for every mini batch becomes flexible, thus increasing the accuracy.\n",
        "    <br>Dropout reduces overfitting by blocking off a fraction of neurons in a layer during training. With that, accuracy increases. </br> </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVArqW8h8zus"
      },
      "source": [
        "g) In real applications, data-centric strategies are essential to train robust deep learning models. Give two (2) examples of such strategies and discuss how the strategies helps improving the model accuracy. **[5 marks]**\n",
        "\n",
        "<span style=\"color:blue\">\n",
        "    <br>1. Data Augmentation: transforms the images such as cropping, rotating and more. It artificially increases the amount of data by generating new data points from the existing data. \n",
        "    <br>2. Data MixUp: combines different features of data from different classes. This is to train the model to learn more and able to think complex.</br> </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zifLt-s8zut"
      },
      "source": [
        "h) Next, implement the two proposed data-centric techniques for the same problem as in the previous question. **[10 marks]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rHNqMSvg8zut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c0b834-4a14-4a24-acbc-e90686170ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "#ii. Data Augmentation: image transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.RandomRotation(degrees=15),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('./data', download=True, train=True, transform=transforms)\n",
        "train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('./data', download=True, train=False, transform=transforms)\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=True)\n",
        "\n",
        "# classes of fashion mnist dataset\n",
        "classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
        "\n",
        "train_data_size = len(train_loader.dataset)\n",
        "test_data_size = len(test_loader.dataset)\n",
        "\n",
        "print(train_data_size)\n",
        "print(test_data_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use CNN MODEL\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3, padding=2)\n",
        "        self.conv5 = nn.Conv2d(512, 512, 1)\n",
        "        self.fc6 = nn.Linear(512 * 1 * 1, 4096)\n",
        "        self.fc7 = nn.Linear(4096, 1000)\n",
        "        self.fc8 = nn.Linear(1000, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = self.pool(self.relu(self.conv4(x)))\n",
        "        x = self.pool(self.relu(self.conv5(x)))\n",
        "        x = x.view(-1, 512 * 1 * 1)\n",
        "        x = self.relu(self.fc6(x))\n",
        "        x = self.relu(self.fc7(x))\n",
        "        x = self.fc8(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rA2x84uEP6-d"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = CNN()\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion4 = nn.CrossEntropyLoss()\n",
        "optimizer3 = optim.SGD(model3.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model3.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP3SwtbNTxwZ",
        "outputId": "1b2597ae-5ae5-46b2-e64d-2e37a2976148"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "  (conv5): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (fc6): Linear(in_features=512, out_features=4096, bias=True)\n",
              "  (fc7): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (fc8): Linear(in_features=1000, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(model3, criterion4, optimizer3, num_epochs)"
      ],
      "metadata": {
        "id": "VkuSe3mRT_Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCy3b5888zut"
      },
      "source": [
        "**QUESTION 2** **[35 marks]**\n",
        "\n",
        "Firstly, watch this video:\n",
        "\n",
        "https://drive.google.com/file/d/1bsypahR7I3f_R3DXkfw_tf0BrbCHxE_O/view?usp=sharing\n",
        "\n",
        "This video shows an example of masked face recognition where the deep learning model is able to detect and classify your face even when wearing a face mask. Using the end-to-end object detection pipeline that you have learned, develop your own masked face recognition such that the model should recognize your face even on face mask while recognize other persons as \"others\".\n",
        "\n",
        "Deliverables for this question are:\n",
        "\n",
        "- the model file. Change the name to <your_name>.pt file (e.g. hasan.pt).\n",
        "- a short video (~10 secs) containing your face and your friends faces (for inference)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "9oIfLdzS8zut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475be8e4-c087-4e62-e08f-c7219121ecd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12351, done.\u001b[K\n",
            "remote: Counting objects: 100% (133/133), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 12351 (delta 77), reused 89 (delta 46), pack-reused 12218\u001b[K\n",
            "Receiving objects: 100% (12351/12351), 12.35 MiB | 13.90 MiB/s, done.\n",
            "Resolving deltas: 100% (8446/8446), done.\n",
            "/content/yolov5/yolov5\n",
            "Setup complete. Using torch 1.12.0+cu113 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH1bXNRMaZ_M",
        "outputId": "43a72edb-7605-41f3-c03f-0caccd9dc18e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=ultralytics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up environment\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "P1IX7Pn1aj73"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after following the link above, recieve python code with these fields filled in\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"qVf147pTmOu3onWV0BSh\")\n",
        "project = rf.workspace(\"dlcv\").project(\"face-pxti8\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cZSeFzEbPSi",
        "outputId": "6be8bb4b-995b-40f2-8997-7a230620a945"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.7/dist-packages (0.2.11)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2)\n",
            "Requirement already satisfied: urllib3==1.26.6 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.26.6)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2021.5.30)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.20.0)\n",
            "Requirement already satisfied: Pillow==9.0.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (9.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.28.1)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: opencv-python-headless==4.2.0.32 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.2.0.32)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.9.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.1.0)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in /content/datasets/Face-1 to yolov5pytorch: 100% [1899082 / 1899082] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to /content/datasets/Face-1 in yolov5pytorch:: 100%|██████████| 190/190 [00:00<00:00, 1220.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knrrPUrOcOvv",
        "outputId": "504e0542-88f7-4bd1-da80-1789881ce564"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/datasets/Face-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.1-347-g7b9cc32 Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 128MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 270 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/Face-1/train/labels.cache' images and labels... 77 found, 0 missing, 0 empty, 0 corrupt: 100% 77/77 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 77/77 [00:00<00:00, 433.97it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/Face-1/valid/labels.cache' images and labels... 8 found, 0 missing, 0 empty, 0 corrupt: 100% 8/8 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 8/8 [00:00<00:00, 137.31it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.87 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/99     1.71G    0.1245   0.01701   0.03223        25       416: 100% 5/5 [00:04<00:00,  1.13it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  7.09it/s]\n",
            "                 all          8          8     0.0021      0.786    0.00495    0.00109\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/99     1.71G    0.1202   0.01798   0.03229        25       416: 100% 5/5 [00:00<00:00,  5.99it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  8.35it/s]\n",
            "                 all          8          8    0.00293        0.5     0.0063    0.00164\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/99     1.71G    0.1066   0.01906   0.02826        25       416: 100% 5/5 [00:00<00:00,  6.03it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  9.20it/s]\n",
            "                 all          8          8    0.00249      0.857     0.0086    0.00206\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/99     1.71G   0.09007   0.02096   0.02595        33       416: 100% 5/5 [00:00<00:00,  6.26it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  9.17it/s]\n",
            "                 all          8          8    0.00325          1     0.0317    0.00495\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/99     1.71G   0.08176   0.02175   0.02374        25       416: 100% 5/5 [00:00<00:00,  6.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  9.50it/s]\n",
            "                 all          8          8    0.00325          1     0.0833     0.0201\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/99     1.71G   0.07844   0.02412   0.02067        35       416: 100% 5/5 [00:00<00:00,  6.47it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  9.65it/s]\n",
            "                 all          8          8     0.0114          1      0.169     0.0561\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/99     1.71G   0.07307   0.02327   0.01864        25       416: 100% 5/5 [00:00<00:00,  6.31it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 10.21it/s]\n",
            "                 all          8          8       0.71      0.261      0.277     0.0932\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/99     1.71G   0.06876   0.02302   0.01549        26       416: 100% 5/5 [00:00<00:00,  6.24it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.01it/s]\n",
            "                 all          8          8          1      0.212      0.377      0.104\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/99     1.71G   0.06447   0.02026   0.01372        27       416: 100% 5/5 [00:00<00:00,  5.79it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 10.70it/s]\n",
            "                 all          8          8      0.266      0.786      0.524      0.147\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/99     1.71G   0.06289   0.02211   0.01188        23       416: 100% 5/5 [00:00<00:00,  6.22it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.38it/s]\n",
            "                 all          8          8      0.304      0.857      0.509       0.16\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/99     1.71G   0.05781   0.02109   0.01046        28       416: 100% 5/5 [00:00<00:00,  6.21it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.25it/s]\n",
            "                 all          8          8      0.219      0.714      0.368      0.159\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/99     1.71G   0.06639   0.01891   0.01251        33       416: 100% 5/5 [00:00<00:00,  6.12it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.67it/s]\n",
            "                 all          8          8      0.181      0.643      0.222     0.0756\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/99     1.71G   0.06866   0.01716  0.008095        20       416: 100% 5/5 [00:00<00:00,  6.37it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.42it/s]\n",
            "                 all          8          8      0.336      0.643       0.62      0.346\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/99     1.71G    0.0712   0.01784  0.008501        29       416: 100% 5/5 [00:00<00:00,  6.17it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.18it/s]\n",
            "                 all          8          8      0.475      0.714      0.494      0.209\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/99     1.71G   0.06385   0.01765  0.007617        21       416: 100% 5/5 [00:00<00:00,  6.02it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.40it/s]\n",
            "                 all          8          8      0.388        0.5      0.623      0.199\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/99     1.71G   0.06633    0.0169   0.00895        25       416: 100% 5/5 [00:00<00:00,  6.19it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.06it/s]\n",
            "                 all          8          8      0.234      0.714      0.355      0.108\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/99     1.71G   0.06429    0.0175  0.006429        29       416: 100% 5/5 [00:00<00:00,  6.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 10.42it/s]\n",
            "                 all          8          8      0.706      0.714      0.867      0.249\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/99     1.71G   0.06663   0.01766  0.006038        18       416: 100% 5/5 [00:00<00:00,  6.38it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.93it/s]\n",
            "                 all          8          8      0.624      0.677       0.85      0.339\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/99     1.71G   0.05597   0.01888  0.006219        28       416: 100% 5/5 [00:00<00:00,  6.35it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 10.80it/s]\n",
            "                 all          8          8      0.779      0.774      0.928       0.33\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/99     1.71G   0.05272   0.01787  0.005482        23       416: 100% 5/5 [00:00<00:00,  6.13it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.23it/s]\n",
            "                 all          8          8       0.18      0.852      0.432      0.179\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/99     1.71G   0.06327   0.01688  0.004982        34       416: 100% 5/5 [00:00<00:00,  6.07it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.54it/s]\n",
            "                 all          8          8      0.485      0.571       0.55      0.266\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/99     1.71G   0.06396   0.01821  0.005196        32       416: 100% 5/5 [00:00<00:00,  6.21it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 10.89it/s]\n",
            "                 all          8          8      0.101      0.555      0.239     0.0843\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/99     1.71G   0.05892    0.0167  0.004876        27       416: 100% 5/5 [00:00<00:00,  6.35it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.20it/s]\n",
            "                 all          8          8      0.469      0.714      0.675      0.272\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/99     1.71G   0.05563   0.01725  0.005326        23       416: 100% 5/5 [00:00<00:00,  6.31it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.81it/s]\n",
            "                 all          8          8      0.683      0.214      0.189     0.0564\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/99     1.71G   0.06032   0.01547  0.004863        31       416: 100% 5/5 [00:00<00:00,  6.30it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.88it/s]\n",
            "                 all          8          8      0.436      0.549      0.514     0.0559\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/99     1.71G   0.06191   0.01409  0.004817        33       416: 100% 5/5 [00:00<00:00,  6.61it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.10it/s]\n",
            "                 all          8          8      0.414      0.505      0.533      0.211\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/99     1.71G   0.05479   0.01487  0.004322        27       416: 100% 5/5 [00:00<00:00,  6.77it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.94it/s]\n",
            "                 all          8          8      0.613      0.571      0.576      0.239\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/99     1.71G   0.05448    0.0178   0.00342        26       416: 100% 5/5 [00:00<00:00,  6.69it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.67it/s]\n",
            "                 all          8          8      0.714      0.709      0.666      0.311\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/99     1.71G   0.04926   0.01695  0.003795        35       416: 100% 5/5 [00:00<00:00,  6.87it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.29it/s]\n",
            "                 all          8          8       0.45      0.714      0.644      0.242\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/99     1.71G   0.05422   0.01541  0.003236        26       416: 100% 5/5 [00:00<00:00,  7.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.75it/s]\n",
            "                 all          8          8      0.736      0.643      0.704      0.396\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     30/99     1.71G   0.04813   0.01497  0.002399        24       416: 100% 5/5 [00:00<00:00,  6.75it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.62it/s]\n",
            "                 all          8          8      0.818      0.714      0.736        0.4\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     31/99     1.71G    0.0483   0.01549  0.003216        24       416: 100% 5/5 [00:00<00:00,  6.66it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.79it/s]\n",
            "                 all          8          8      0.556      0.714      0.657      0.297\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     32/99     1.71G   0.05748   0.01581  0.002461        30       416: 100% 5/5 [00:00<00:00,  7.11it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.77it/s]\n",
            "                 all          8          8       0.54      0.786      0.663      0.286\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     33/99     1.71G   0.05486    0.0136  0.002527        24       416: 100% 5/5 [00:00<00:00,  6.81it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.39it/s]\n",
            "                 all          8          8      0.592      0.714      0.747      0.299\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     34/99     1.71G   0.05034   0.01634  0.002375        31       416: 100% 5/5 [00:00<00:00,  7.08it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.69it/s]\n",
            "                 all          8          8       0.61      0.722      0.712      0.244\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     35/99     1.71G   0.04737   0.01607  0.001943        33       416: 100% 5/5 [00:00<00:00,  6.85it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.24it/s]\n",
            "                 all          8          8      0.514      0.714      0.588      0.183\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     36/99     1.71G   0.05406    0.0144  0.001801        30       416: 100% 5/5 [00:00<00:00,  6.84it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.12it/s]\n",
            "                 all          8          8      0.669      0.695       0.73      0.215\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     37/99     1.71G   0.05135     0.016  0.002953        32       416: 100% 5/5 [00:00<00:00,  6.65it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.07it/s]\n",
            "                 all          8          8      0.578      0.643      0.734      0.212\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     38/99     1.71G   0.04495   0.01653  0.003521        32       416: 100% 5/5 [00:00<00:00,  6.80it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.39it/s]\n",
            "                 all          8          8      0.785      0.714      0.751      0.268\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     39/99     1.71G   0.04343   0.01543  0.002168        28       416: 100% 5/5 [00:00<00:00,  6.53it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.92it/s]\n",
            "                 all          8          8      0.621       0.77      0.679      0.187\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     40/99     1.71G   0.05008   0.01372  0.002359        26       416: 100% 5/5 [00:00<00:00,  6.94it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.84it/s]\n",
            "                 all          8          8      0.683      0.929      0.837      0.311\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     41/99     1.71G   0.04444   0.01355  0.002102        29       416: 100% 5/5 [00:00<00:00,  6.90it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.78it/s]\n",
            "                 all          8          8      0.883      0.857      0.915      0.295\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     42/99     1.71G   0.04501   0.01373  0.002749        30       416: 100% 5/5 [00:00<00:00,  6.98it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.96it/s]\n",
            "                 all          8          8      0.895      0.875      0.926      0.355\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     43/99     1.71G   0.04077   0.01479  0.002758        27       416: 100% 5/5 [00:00<00:00,  6.25it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.34it/s]\n",
            "                 all          8          8      0.929      0.836      0.927      0.378\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     44/99     1.71G   0.04624   0.01579  0.001832        31       416: 100% 5/5 [00:00<00:00,  6.99it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.38it/s]\n",
            "                 all          8          8      0.749      0.786      0.857      0.218\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     45/99     1.71G   0.04443   0.01474  0.001404        32       416: 100% 5/5 [00:00<00:00,  6.78it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.11it/s]\n",
            "                 all          8          8       0.95      0.804      0.942       0.37\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     46/99     1.71G   0.03825    0.0126  0.001262        26       416: 100% 5/5 [00:00<00:00,  7.10it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.49it/s]\n",
            "                 all          8          8      0.855      0.908      0.956      0.416\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     47/99     1.71G   0.03953   0.01371  0.002137        24       416: 100% 5/5 [00:00<00:00,  6.25it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.94it/s]\n",
            "                 all          8          8      0.919       0.82      0.944       0.29\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     48/99     1.71G   0.04643   0.01337  0.001631        28       416: 100% 5/5 [00:00<00:00,  7.32it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.56it/s]\n",
            "                 all          8          8      0.887      0.786      0.914      0.349\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     49/99     1.71G   0.04578    0.0129   0.00243        31       416: 100% 5/5 [00:00<00:00,  6.85it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.26it/s]\n",
            "                 all          8          8      0.853      0.786      0.886      0.306\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     50/99     1.71G   0.03654   0.01405  0.001264        29       416: 100% 5/5 [00:00<00:00,  6.89it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.86it/s]\n",
            "                 all          8          8      0.875      0.929       0.94      0.299\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     51/99     1.71G   0.03596   0.01328   0.00146        30       416: 100% 5/5 [00:00<00:00,  6.61it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.66it/s]\n",
            "                 all          8          8      0.815      0.864      0.881      0.282\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     52/99     1.71G   0.04293   0.01314  0.001696        28       416: 100% 5/5 [00:00<00:00,  6.81it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.67it/s]\n",
            "                 all          8          8       0.83      0.857      0.828      0.322\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     53/99     1.71G   0.04295   0.01427  0.001327        33       416: 100% 5/5 [00:00<00:00,  6.81it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.81it/s]\n",
            "                 all          8          8      0.825      0.865      0.841      0.357\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     54/99     1.71G   0.03725    0.0128  0.001426        29       416: 100% 5/5 [00:00<00:00,  7.27it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.31it/s]\n",
            "                 all          8          8      0.813      0.857      0.839      0.382\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     55/99     1.71G   0.03688   0.01266  0.001351        31       416: 100% 5/5 [00:00<00:00,  6.68it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.24it/s]\n",
            "                 all          8          8      0.817      0.857      0.806      0.305\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     56/99     1.71G    0.0388   0.01237  0.001712        20       416: 100% 5/5 [00:00<00:00,  7.15it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.80it/s]\n",
            "                 all          8          8      0.819      0.857      0.822      0.423\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     57/99     1.71G   0.03633   0.01194  0.001397        29       416: 100% 5/5 [00:00<00:00,  6.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.47it/s]\n",
            "                 all          8          8      0.821      0.842      0.884       0.33\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     58/99     1.71G   0.03454   0.01231  0.001813        28       416: 100% 5/5 [00:00<00:00,  6.91it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.89it/s]\n",
            "                 all          8          8      0.835      0.847      0.843      0.367\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     59/99     1.71G   0.03867   0.01316  0.001154        25       416: 100% 5/5 [00:00<00:00,  6.39it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.21it/s]\n",
            "                 all          8          8      0.833      0.845        0.8      0.315\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     60/99     1.71G   0.03882   0.01331  0.001566        38       416: 100% 5/5 [00:01<00:00,  4.99it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  5.88it/s]\n",
            "                 all          8          8      0.825      0.856      0.834      0.352\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     61/99     1.71G   0.04064   0.01315  0.001432        32       416: 100% 5/5 [00:01<00:00,  3.61it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  8.67it/s]\n",
            "                 all          8          8      0.805      0.857      0.821      0.322\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     62/99     1.71G   0.03491   0.01254  0.003789        26       416: 100% 5/5 [00:00<00:00,  7.03it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.13it/s]\n",
            "                 all          8          8      0.787      0.857      0.832      0.385\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     63/99     1.71G   0.03645   0.01285  0.003103        24       416: 100% 5/5 [00:00<00:00,  6.75it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.64it/s]\n",
            "                 all          8          8       0.82      0.857      0.856      0.399\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     64/99     1.71G   0.03317   0.01312  0.001203        32       416: 100% 5/5 [00:00<00:00,  6.98it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.49it/s]\n",
            "                 all          8          8      0.836      0.857      0.828      0.309\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     65/99     1.71G   0.03553   0.01255  0.001336        29       416: 100% 5/5 [00:00<00:00,  6.70it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.70it/s]\n",
            "                 all          8          8      0.828      0.857      0.807      0.353\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     66/99     1.71G   0.03497   0.01257  0.001134        26       416: 100% 5/5 [00:00<00:00,  6.88it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.12it/s]\n",
            "                 all          8          8      0.812      0.857      0.815      0.382\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     67/99     1.71G   0.03552   0.01235 0.0009651        25       416: 100% 5/5 [00:00<00:00,  6.73it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.28it/s]\n",
            "                 all          8          8      0.816      0.857      0.836      0.381\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     68/99     1.71G   0.03457   0.01269 0.0008949        29       416: 100% 5/5 [00:00<00:00,  7.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.89it/s]\n",
            "                 all          8          8      0.836      0.857       0.85      0.423\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     69/99     1.71G   0.03507    0.0122 0.0008453        33       416: 100% 5/5 [00:00<00:00,  5.78it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.08it/s]\n",
            "                 all          8          8      0.836      0.857      0.859      0.436\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     70/99     1.71G   0.03224   0.01156 0.0008145        29       416: 100% 5/5 [00:00<00:00,  6.91it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.38it/s]\n",
            "                 all          8          8      0.892      0.929      0.879      0.394\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     71/99     1.71G   0.03283   0.01225  0.001049        29       416: 100% 5/5 [00:00<00:00,  6.67it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.20it/s]\n",
            "                 all          8          8      0.862      0.857      0.826       0.39\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     72/99     1.71G   0.03417   0.01211  0.001573        23       416: 100% 5/5 [00:00<00:00,  6.72it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.88it/s]\n",
            "                 all          8          8      0.886      0.929      0.878      0.406\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     73/99     1.71G   0.03365   0.01167 0.0009017        28       416: 100% 5/5 [00:00<00:00,  7.19it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.11it/s]\n",
            "                 all          8          8      0.892      0.857      0.826      0.339\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     74/99     1.71G   0.03082    0.0114 0.0009757        25       416: 100% 5/5 [00:00<00:00,  7.05it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.85it/s]\n",
            "                 all          8          8      0.894      0.843      0.825      0.327\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     75/99     1.71G    0.0317   0.01158 0.0007399        32       416: 100% 5/5 [00:00<00:00,  6.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.02it/s]\n",
            "                 all          8          8      0.791      0.857      0.807      0.375\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     76/99     1.71G   0.03033   0.01208 0.0008692        30       416: 100% 5/5 [00:00<00:00,  7.22it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.79it/s]\n",
            "                 all          8          8      0.792      0.857      0.807      0.338\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     77/99     1.71G   0.03197   0.01095 0.0007844        29       416: 100% 5/5 [00:00<00:00,  7.09it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.78it/s]\n",
            "                 all          8          8      0.792      0.849      0.821      0.378\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     78/99     1.71G   0.03331    0.0132 0.0008841        29       416: 100% 5/5 [00:00<00:00,  6.89it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.29it/s]\n",
            "                 all          8          8      0.798      0.848      0.821       0.39\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     79/99     1.71G   0.03039   0.01217 0.0008138        26       416: 100% 5/5 [00:00<00:00,  6.60it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 15.38it/s]\n",
            "                 all          8          8      0.809       0.85      0.822      0.455\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     80/99     1.71G   0.03323   0.01169 0.0008073        33       416: 100% 5/5 [00:00<00:00,  6.95it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.18it/s]\n",
            "                 all          8          8      0.817      0.854      0.823      0.434\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     81/99     1.71G   0.03331    0.0129 0.0009089        39       416: 100% 5/5 [00:00<00:00,  6.79it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 11.96it/s]\n",
            "                 all          8          8      0.833      0.856      0.823       0.39\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     82/99     1.71G   0.03154   0.01109 0.0008772        27       416: 100% 5/5 [00:00<00:00,  7.02it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.95it/s]\n",
            "                 all          8          8      0.836      0.857      0.822      0.445\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     83/99     1.71G   0.03292   0.01164 0.0006672        23       416: 100% 5/5 [00:00<00:00,  6.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.79it/s]\n",
            "                 all          8          8      0.831      0.857      0.826      0.439\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     84/99     1.71G   0.03131   0.01149  0.001048        23       416: 100% 5/5 [00:00<00:00,  6.65it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.71it/s]\n",
            "                 all          8          8      0.832      0.857      0.822      0.445\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     85/99     1.71G     0.029  0.009977 0.0009216        19       416: 100% 5/5 [00:00<00:00,  6.95it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.74it/s]\n",
            "                 all          8          8       0.83      0.857      0.823      0.444\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     86/99     1.71G   0.03125   0.01218  0.000879        30       416: 100% 5/5 [00:00<00:00,  7.00it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.41it/s]\n",
            "                 all          8          8      0.828      0.857      0.823      0.449\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     87/99     1.71G   0.03062   0.01121 0.0008605        27       416: 100% 5/5 [00:00<00:00,  6.48it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.70it/s]\n",
            "                 all          8          8      0.896      0.929      0.898      0.454\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     88/99     1.71G    0.0282    0.0109 0.0005064        25       416: 100% 5/5 [00:00<00:00,  6.64it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.39it/s]\n",
            "                 all          8          8      0.895      0.929        0.9      0.444\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     89/99     1.71G   0.02759    0.0107 0.0005934        25       416: 100% 5/5 [00:00<00:00,  6.82it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.21it/s]\n",
            "                 all          8          8      0.826      0.857       0.83      0.395\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     90/99     1.71G    0.0291   0.01141 0.0005364        32       416: 100% 5/5 [00:00<00:00,  6.37it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.44it/s]\n",
            "                 all          8          8      0.896      0.929       0.89      0.406\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     91/99     1.71G   0.02771   0.01158 0.0005952        20       416: 100% 5/5 [00:00<00:00,  6.38it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.24it/s]\n",
            "                 all          8          8      0.826      0.857       0.82      0.382\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     92/99     1.71G   0.02931   0.01212  0.001554        28       416: 100% 5/5 [00:00<00:00,  6.40it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.88it/s]\n",
            "                 all          8          8      0.826      0.857      0.779      0.414\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     93/99     1.71G   0.02701   0.01122 0.0008556        24       416: 100% 5/5 [00:00<00:00,  6.53it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.46it/s]\n",
            "                 all          8          8      0.824      0.857      0.778      0.401\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     94/99     1.71G   0.02808   0.01164  0.001506        30       416: 100% 5/5 [00:00<00:00,  6.66it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.53it/s]\n",
            "                 all          8          8      0.824      0.857      0.778      0.405\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     95/99     1.71G   0.02774   0.01284  0.001105        24       416: 100% 5/5 [00:00<00:00,  6.33it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 13.89it/s]\n",
            "                 all          8          8      0.825      0.857      0.778      0.408\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     96/99     1.71G   0.03078   0.01154  0.001062        27       416: 100% 5/5 [00:00<00:00,  6.85it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.80it/s]\n",
            "                 all          8          8      0.827      0.857      0.779      0.406\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     97/99     1.71G   0.02934   0.01124 0.0006161        29       416: 100% 5/5 [00:00<00:00,  5.98it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.33it/s]\n",
            "                 all          8          8      0.828      0.857      0.762      0.401\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     98/99     1.71G   0.02731   0.01211 0.0005531        24       416: 100% 5/5 [00:00<00:00,  6.74it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 14.23it/s]\n",
            "                 all          8          8      0.828      0.857      0.762      0.401\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     99/99     1.71G   0.02694   0.01188  0.000662        29       416: 100% 5/5 [00:00<00:00,  6.44it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00, 12.61it/s]\n",
            "                 all          8          8      0.828      0.857      0.765      0.404\n",
            "\n",
            "100 epochs completed in 0.036 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  9.64it/s]\n",
            "                 all          8          8      0.896      0.929      0.898      0.454\n",
            "                  Me          8          1      0.955          1      0.995      0.497\n",
            "              Others          8          7      0.838      0.857      0.802      0.411\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyZztJQVcPU5",
        "outputId": "fbc42966-5206-4135-9c0c-f202de1b9d88"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/datasets/Face-1/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-347-g7b9cc32 Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/4 /content/datasets/Face-1/test/images/WIN_20220801_12_38_51_Pro_jpg.rf.d8fa4925108a411750c4bf11b12ebec5.jpg: 416x416 1 Others, Done. (0.012s)\n",
            "image 2/4 /content/datasets/Face-1/test/images/WIN_20220801_12_40_30_Pro_jpg.rf.9f1d5ea63f6eb79f0f44a81dd1df3171.jpg: 416x416 Done. (0.009s)\n",
            "image 3/4 /content/datasets/Face-1/test/images/WIN_20220801_12_43_49_Pro_jpg.rf.2c0ff45bf5e9745861a9fc80d8de1cb1.jpg: 416x416 1 Others, Done. (0.014s)\n",
            "image 4/4 /content/datasets/Face-1/test/images/WIN_20220801_12_44_29_Pro_jpg.rf.ae7726f94f714dedae79c6f28088338f.jpg: 416x416 2 Otherss, Done. (0.013s)\n",
            "Speed: 0.4ms pre-process, 12.0ms inference, 1.2ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "rW5TkKHAcYgD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export your model's weights for future use\n",
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pq5yg0g8cdVp",
        "outputId": "725ee422-e376-4dcd-fa6e-d3e16a02f33a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9c31bc45-1964-4911-b02f-443664a37216\", \"best.pt\", 14339381)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hk5RMYEtiXp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch-yolo",
      "language": "python",
      "name": "pytorch-yolo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "1910230_Assessment1_DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9549e96fc794ffe9b94c91433f3d103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4f7c83b7e7d4b78a11d389db5f303e8",
              "IPY_MODEL_2c2c9ca375d94e70b1edf76003941150",
              "IPY_MODEL_fd47839b98794336bc8c4fbf4c5ec72e"
            ],
            "layout": "IPY_MODEL_47bf47de2dc5417a8f721432c755ae54"
          }
        },
        "f4f7c83b7e7d4b78a11d389db5f303e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96df4e5d6fb84b388bc0d3a030df205d",
            "placeholder": "​",
            "style": "IPY_MODEL_612acdb6f82646959f1c47ee2f0d03aa",
            "value": "100%"
          }
        },
        "2c2c9ca375d94e70b1edf76003941150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca2c1816b56f46a380b2c464f7b106cf",
            "max": 26421880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b75a48d820c14df2893d5f2af4f0cef7",
            "value": 26421880
          }
        },
        "fd47839b98794336bc8c4fbf4c5ec72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec46d8c8011b481ea58decf4a5865e87",
            "placeholder": "​",
            "style": "IPY_MODEL_87d1d591896d41ab9a88041a37513999",
            "value": " 26421880/26421880 [00:01&lt;00:00, 25134323.62it/s]"
          }
        },
        "47bf47de2dc5417a8f721432c755ae54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96df4e5d6fb84b388bc0d3a030df205d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "612acdb6f82646959f1c47ee2f0d03aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca2c1816b56f46a380b2c464f7b106cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b75a48d820c14df2893d5f2af4f0cef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec46d8c8011b481ea58decf4a5865e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d1d591896d41ab9a88041a37513999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65d0880e3b464648a1b34d1451ed3953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60d8898020c448899b4068867520fed0",
              "IPY_MODEL_ae48b10cb20f45c8ab62e238c24727c2",
              "IPY_MODEL_d1368d494b334b51b97944bde8be34a0"
            ],
            "layout": "IPY_MODEL_f9ace680701f4daea623ac20e6d4ba08"
          }
        },
        "60d8898020c448899b4068867520fed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_636b0bb2f0b64be6b3e3cf209b1c20df",
            "placeholder": "​",
            "style": "IPY_MODEL_9e47ca669de44dd59534297de1e1364e",
            "value": "100%"
          }
        },
        "ae48b10cb20f45c8ab62e238c24727c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624feaeab71648be868a13555dda6323",
            "max": 29515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d7c1abfd3034189bc81e9737c067a5e",
            "value": 29515
          }
        },
        "d1368d494b334b51b97944bde8be34a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51b78bd8d2d8454ba36869c5f6b2cd2c",
            "placeholder": "​",
            "style": "IPY_MODEL_954a1d03f2734d8cbeae992b1787b380",
            "value": " 29515/29515 [00:00&lt;00:00, 262308.41it/s]"
          }
        },
        "f9ace680701f4daea623ac20e6d4ba08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636b0bb2f0b64be6b3e3cf209b1c20df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e47ca669de44dd59534297de1e1364e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "624feaeab71648be868a13555dda6323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d7c1abfd3034189bc81e9737c067a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51b78bd8d2d8454ba36869c5f6b2cd2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "954a1d03f2734d8cbeae992b1787b380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e5a99203e2e47bebe7cdcd5ef85a87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af442801ba884d3d93b663decb7f9c86",
              "IPY_MODEL_6aaaf93609ca4499915215aef7a78158",
              "IPY_MODEL_e2ab9dfae8394eb3abf97fdaa44180a6"
            ],
            "layout": "IPY_MODEL_baccb0946d504b50bd477b5311d5b661"
          }
        },
        "af442801ba884d3d93b663decb7f9c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c34f7fc3954791a45e2a4ab6ae08cf",
            "placeholder": "​",
            "style": "IPY_MODEL_7ed6e0dd9a974768ba4c021f5f883085",
            "value": "100%"
          }
        },
        "6aaaf93609ca4499915215aef7a78158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bc8ed2b704b41e0b26c0baceb8b7799",
            "max": 4422102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92f50b50640241a88aa46d2157fb2cbd",
            "value": 4422102
          }
        },
        "e2ab9dfae8394eb3abf97fdaa44180a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d25a927002b459f95a40058d0689fed",
            "placeholder": "​",
            "style": "IPY_MODEL_882cc8a4f2284df9bf1e4ad4c384a103",
            "value": " 4422102/4422102 [00:00&lt;00:00, 8558508.27it/s]"
          }
        },
        "baccb0946d504b50bd477b5311d5b661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c34f7fc3954791a45e2a4ab6ae08cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed6e0dd9a974768ba4c021f5f883085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bc8ed2b704b41e0b26c0baceb8b7799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f50b50640241a88aa46d2157fb2cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d25a927002b459f95a40058d0689fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "882cc8a4f2284df9bf1e4ad4c384a103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a3f7182c6d6469690ed4dc190a40652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50edf6972be448fca2883e4be2c671a7",
              "IPY_MODEL_540e9ab5e7c44d1485e3740028f3603d",
              "IPY_MODEL_a7658cb301a74dc385c359c027427e0e"
            ],
            "layout": "IPY_MODEL_dac90f7cafee442ebf9019c6bad712e7"
          }
        },
        "50edf6972be448fca2883e4be2c671a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c9ba3c21b24ccbadc12dff3e49b441",
            "placeholder": "​",
            "style": "IPY_MODEL_32c38e0f2d9f4097ad4e0516d6e74f30",
            "value": "100%"
          }
        },
        "540e9ab5e7c44d1485e3740028f3603d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6241ae7d584f4fb7ac8fdffec905f3fc",
            "max": 5148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3160bf952d334e54a0ec7d1bd538d7de",
            "value": 5148
          }
        },
        "a7658cb301a74dc385c359c027427e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bfe5383d1554944b835ce2a81960aaa",
            "placeholder": "​",
            "style": "IPY_MODEL_933c4ca6d559416d87584f438afc8605",
            "value": " 5148/5148 [00:00&lt;00:00, 98994.01it/s]"
          }
        },
        "dac90f7cafee442ebf9019c6bad712e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c9ba3c21b24ccbadc12dff3e49b441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c38e0f2d9f4097ad4e0516d6e74f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6241ae7d584f4fb7ac8fdffec905f3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3160bf952d334e54a0ec7d1bd538d7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bfe5383d1554944b835ce2a81960aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "933c4ca6d559416d87584f438afc8605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d35299a47df47f585f7bb233d17fefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0018f06aa094dec9eb23e7ba212cf38",
              "IPY_MODEL_abc1ef82e7ac485ebeb101351b772c3b",
              "IPY_MODEL_169be653eaf043f4bb9ca999d5abed03"
            ],
            "layout": "IPY_MODEL_3786452fa2aa4e4e82fe1848c06e2d36"
          }
        },
        "d0018f06aa094dec9eb23e7ba212cf38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab3e3687293c4a9a9a6525b82f32faeb",
            "placeholder": "​",
            "style": "IPY_MODEL_1025fe6adefd4294a61517e4cc9628b4",
            "value": "100%"
          }
        },
        "abc1ef82e7ac485ebeb101351b772c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d75c9b232ad84c27bb6c940e0a8438ac",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b4a53d10c8b454e857638a82c375721",
            "value": 102530333
          }
        },
        "169be653eaf043f4bb9ca999d5abed03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3126ec1ae8c49529abd153a035a2f01",
            "placeholder": "​",
            "style": "IPY_MODEL_20c88a8017b44ea6890744c20e74ff90",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 172MB/s]"
          }
        },
        "3786452fa2aa4e4e82fe1848c06e2d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3e3687293c4a9a9a6525b82f32faeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1025fe6adefd4294a61517e4cc9628b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d75c9b232ad84c27bb6c940e0a8438ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b4a53d10c8b454e857638a82c375721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3126ec1ae8c49529abd153a035a2f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c88a8017b44ea6890744c20e74ff90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}